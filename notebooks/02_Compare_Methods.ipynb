{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Compare Deduplication Methods\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this exercise, you will:\n",
    "- Compare different deduplication strategies\n",
    "- Understand when to use each method\n",
    "- Analyze performance differences\n",
    "\n",
    "## Overview\n",
    "\n",
    "Different deduplication methods work better for different scenarios:\n",
    "\n",
    "**Fast Methods (Recommended for most cases):**\n",
    "- **exact**: Fastest, removes exact duplicates\n",
    "- **normalized**: Handles case/whitespace variations\n",
    "- **spark_hash**: Very fast hash-based deduplication\n",
    "- **checksum_md5**: MD5 hash-based deduplication\n",
    "- **checksum_sha256**: SHA-256 hash-based deduplication\n",
    "- **partitioned_hash**: Hash-based partitioned deduplication (for large datasets)\n",
    "\n",
    "**Advanced Methods:**\n",
    "- **window**: Window-based deduplication (keeps first/last record)\n",
    "- **lsh**: Locality-Sensitive Hashing for scalable fuzzy matching\n",
    "\n",
    "**Fuzzy Matching (Expensive, use only for small datasets):**\n",
    "- **fuzzy_levenshtein**: Fuzzy matching with Levenshtein distance\n",
    "- **fuzzy_fuzzywuzzy**: Fuzzy matching with FuzzyWuzzy library\n",
    "\n",
    "This exercise will compare all available methods to help you understand their performance characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Add project root to Python path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Find project root\n",
    "current_dir = os.getcwd()\n",
    "if 'notebooks' in current_dir:\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "elif os.path.exists(os.path.join(current_dir, 'deduplicate_spark.py')):\n",
    "    project_root = current_dir\n",
    "else:\n",
    "    # Search up directories\n",
    "    test_dir = current_dir\n",
    "    for _ in range(5):\n",
    "        if os.path.exists(os.path.join(test_dir, 'deduplicate_spark.py')):\n",
    "            project_root = test_dir\n",
    "            break\n",
    "        parent = os.path.dirname(test_dir)\n",
    "        if parent == test_dir:\n",
    "            break\n",
    "        test_dir = parent\n",
    "    project_root = project_root or current_dir\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"✓ Added to Python path: {project_root}\")\n",
    "\n",
    "# Change to project root for file operations\n",
    "os.chdir(project_root)\n",
    "print(f\"✓ Changed working directory to: {project_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deduplicate_spark import create_spark_session, process_file_spark\n",
    "import time\n",
    "\n",
    "spark = create_spark_session(\"Exercise2_CompareMethods\")\n",
    "print(\"✓ Spark session created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All available methods to test\n",
    "# Note: fuzzy methods are expensive and may take a long time for large datasets\n",
    "all_methods = [\n",
    "    # Fast methods (recommended)\n",
    "    'exact',\n",
    "    'normalized', \n",
    "    'spark_hash',\n",
    "    'checksum_md5',\n",
    "    'checksum_sha256',\n",
    "    'partitioned_hash',\n",
    "    # Advanced methods\n",
    "    'window',\n",
    "    'lsh',\n",
    "    # Fuzzy methods (expensive - may skip for large datasets)\n",
    "    'fuzzy_levenshtein',\n",
    "    'fuzzy_fuzzywuzzy'\n",
    "]\n",
    "\n",
    "# For this exercise, we'll test all methods\n",
    "# If you have a very large dataset, you may want to skip fuzzy methods\n",
    "methods_to_test = all_methods\n",
    "\n",
    "# Uncomment below to skip expensive fuzzy methods for large datasets:\n",
    "# methods_to_test = [m for m in all_methods if not m.startswith('fuzzy')]\n",
    "\n",
    "print(f\"Testing {len(methods_to_test)} deduplication methods...\")\n",
    "print(f\"Data file: {os.path.join(project_root, 'data', 'redundant_data.csv')}\\n\")\n",
    "\n",
    "results = []\n",
    "data_file = os.path.join(project_root, \"data\", \"redundant_data.csv\")\n",
    "\n",
    "for i, method in enumerate(methods_to_test, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"[{i}/{len(methods_to_test)}] Testing method: {method}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        stats = process_file_spark(spark, data_file, method=method)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        if stats:\n",
    "            results.append({\n",
    "                'method': method,\n",
    "                'original_count': stats['original_count'],\n",
    "                'unique_count': stats['unique_count'],\n",
    "                'duplicates_removed': stats['duplicates_removed'],\n",
    "                'deduplication_rate': stats['deduplication_rate'],\n",
    "                'time_seconds': round(elapsed_time, 2)\n",
    "            })\n",
    "            print(f\"✓ Completed in {elapsed_time:.2f} seconds\")\n",
    "            print(f\"  - Original: {stats['original_count']:,} records\")\n",
    "            print(f\"  - Unique: {stats['unique_count']:,} records\")\n",
    "            print(f\"  - Removed: {stats['duplicates_removed']:,} duplicates ({stats['deduplication_rate']:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"✗ Method {method} returned no results\")\n",
    "            results.append({\n",
    "                'method': method,\n",
    "                'original_count': 0,\n",
    "                'unique_count': 0,\n",
    "                'duplicates_removed': 0,\n",
    "                'deduplication_rate': 0.0,\n",
    "                'time_seconds': elapsed_time\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error with method {method}: {e}\")\n",
    "        results.append({\n",
    "            'method': method,\n",
    "            'original_count': 0,\n",
    "            'unique_count': 0,\n",
    "            'duplicates_removed': 0,\n",
    "            'deduplication_rate': 0.0,\n",
    "            'time_seconds': 0.0,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Display comparison\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"COMPARISON RESULTS\")\n",
    "print('='*70)\n",
    "\n",
    "import pandas as pd\n",
    "if results:\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Sort by time (fastest first)\n",
    "    df_results = df_results.sort_values('time_seconds')\n",
    "    \n",
    "    # Display full results\n",
    "    print(\"\\nFull Results (sorted by execution time):\")\n",
    "    print(df_results.to_string(index=False))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nFastest method: {df_results.iloc[0]['method']} ({df_results.iloc[0]['time_seconds']}s)\")\n",
    "    print(f\"Slowest method: {df_results.iloc[-1]['method']} ({df_results.iloc[-1]['time_seconds']}s)\")\n",
    "    \n",
    "    # Methods with highest deduplication rate\n",
    "    if 'deduplication_rate' in df_results.columns:\n",
    "        best_dedup = df_results.loc[df_results['deduplication_rate'].idxmax()]\n",
    "        print(f\"\\nHighest deduplication rate: {best_dedup['method']} ({best_dedup['deduplication_rate']:.2f}%)\")\n",
    "    \n",
    "    # Group by category\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PERFORMANCE BY CATEGORY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    fast_methods = df_results[df_results['method'].isin(['exact', 'normalized', 'spark_hash', 'checksum_md5', 'checksum_sha256', 'partitioned_hash'])]\n",
    "    if len(fast_methods) > 0:\n",
    "        print(\"\\nFast Methods (recommended):\")\n",
    "        print(fast_methods[['method', 'time_seconds', 'deduplication_rate']].to_string(index=False))\n",
    "    \n",
    "    advanced_methods = df_results[df_results['method'].isin(['window', 'lsh'])]\n",
    "    if len(advanced_methods) > 0:\n",
    "        print(\"\\nAdvanced Methods:\")\n",
    "        print(advanced_methods[['method', 'time_seconds', 'deduplication_rate']].to_string(index=False))\n",
    "    \n",
    "    fuzzy_methods = df_results[df_results['method'].str.startswith('fuzzy')]\n",
    "    if len(fuzzy_methods) > 0:\n",
    "        print(\"\\nFuzzy Methods (expensive):\")\n",
    "        print(fuzzy_methods[['method', 'time_seconds', 'deduplication_rate']].to_string(index=False))\n",
    "else:\n",
    "    print(\"No results to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to Answer\n",
    "\n",
    "1. **Which method was fastest?** Compare the execution times.\n",
    "2. **Which method removed the most duplicates?** Check the deduplication rates.\n",
    "3. **What's the trade-off between speed and accuracy?** Do faster methods find fewer duplicates?\n",
    "4. **When would you use each method?**\n",
    "   - For exact duplicates: Use `exact` or `spark_hash`\n",
    "   - For case/whitespace variations: Use `normalized`\n",
    "   - For large datasets: Use `partitioned_hash` or `spark_hash`\n",
    "   - For fuzzy matching: Use `lsh` (scalable) or `fuzzy_levenshtein`/`fuzzy_fuzzywuzzy` (small datasets only)\n",
    "5. **Which method would you recommend for production use?** Consider both speed and deduplication effectiveness.\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Fast methods** (`exact`, `spark_hash`, `checksum_*`) are best for most production scenarios\n",
    "- **Fuzzy methods** are very expensive and should only be used for small datasets or when exact matching isn't sufficient\n",
    "- **LSH** provides a good balance for fuzzy matching on larger datasets\n",
    "- **Normalized** deduplication is useful when data has inconsistent formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"✓ Spark session stopped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
