{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Basic Deduplication\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this exercise, you will:\n",
    "- Learn how to remove exact duplicates from a dataset\n",
    "- Understand the `exact` deduplication method\n",
    "- Analyze deduplication results\n",
    "- See where results are saved\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `exact` method is the simplest and fastest deduplication technique. It removes records that are exactly the same based on specified columns (typically `name` and `email`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deduplicate_spark import create_spark_session, process_file_spark\n",
    "\n",
    "# Create Spark session\n",
    "spark = create_spark_session(\"Exercise1_BasicDeduplication\")\n",
    "print(\"\u2713 Spark session created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate or Load Data\n",
    "\n",
    "If you haven't generated data yet, uncomment and run the cell below. Otherwise, we'll use existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Generate data if it doesn't exist\n",
    "if not os.path.exists(\"data/exercise1.csv\"):\n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "    \n",
    "    print(\"Generating sample data...\")\n",
    "    result = subprocess.run(\n",
    "        [\"python\", \"generate_dataset.py\", \"1000\", \"data/exercise1.csv\"],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(\"\u2713 Data generated successfully\")\n",
    "    else:\n",
    "        print(f\"\u2717 Error: {result.stderr}\")\n",
    "else:\n",
    "    print(\"\u2713 Using existing data file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Deduplication\n",
    "\n",
    "Now let's run the exact deduplication method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run exact deduplication\n",
    "stats = process_file_spark(\n",
    "    spark,\n",
    "    \"data/exercise1.csv\",\n",
    "    output_dir=None,  # Uses /tmp/results in Cloudera, data/ locally\n",
    "    method='exact'\n",
    ")\n",
    "\n",
    "if stats:\n",
    "    print(f\"\\nOriginal records: {stats['original_count']:,}\")\n",
    "    print(f\"Unique records: {stats['unique_count']:,}\")\n",
    "    print(f\"Duplicates removed: {stats['duplicates_removed']:,}\")\n",
    "    print(f\"Deduplication rate: {stats['deduplication_rate']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to Answer\n",
    "\n",
    "1. How many duplicates were found?\n",
    "2. What percentage of records were duplicates?\n",
    "3. Where are the results saved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "spark.stop()\n",
    "print(\"\u2713 Spark session stopped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}